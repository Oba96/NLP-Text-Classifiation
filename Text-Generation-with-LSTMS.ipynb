{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bff9a67-5560-42b2-a0af-2a78976d64ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "    \n",
    "    return str_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5938796-ec77-437f-b8b3-f160f54c0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a815ea-c47a-4f4c-aaac-d6290a59c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb37ab03-a474-423f-ad5e-4e3ca08cbd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1482602-feb2-4f55-aef7-01c6c4cf681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c98b17e-c1b2-47db-b37f-473aa98a29ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_file('C:\\\\Users\\\\eobuobi\\\\trial\\\\nlp_project\\\\data\\\\raw\\\\moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87221184-09fb-409a-9c4c-989a64a9e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = separate_punc(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c99472a-3105-43f8-9bb4-7e488bd331b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11338"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a1b4bea-17b5-4a05-98e4-e1a2a83b4976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#25words --> network will predict #26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c71eef5b-5d97-469e-862f-040303f86d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 25 + 1\n",
    "\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    seq = tokens[i-train_len:i]\n",
    "    \n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e3af1fc-735a-49e7-979b-1a242bf95c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fad40c6a-8f95-413f-9d03-53a169ed5717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5261cdc5-8bba-4d41-a441-bb62f69c4f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8a82d3f-baa6-4b76-8190-497418a2ee5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0325379-e05b-41fd-aaa3-7a773dcae14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce695c7c-65c1-495b-ae96-1c7c8e1def73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c4b75b1-87e6-4d0b-afb5-681a9b3def7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f11137d1-d020-4ace-94ed-17478d9161a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#id to a word\n",
    "# sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c236670-57e6-4163-a542-392b8e6d3a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956 : call\n",
      "14 : me\n",
      "263 : ishmael\n",
      "51 : some\n",
      "261 : years\n",
      "408 : ago\n",
      "87 : never\n",
      "219 : mind\n",
      "129 : how\n",
      "111 : long\n",
      "954 : precisely\n",
      "260 : having\n",
      "50 : little\n",
      "43 : or\n",
      "38 : no\n",
      "315 : money\n",
      "7 : in\n",
      "23 : my\n",
      "546 : purse\n",
      "3 : and\n",
      "150 : nothing\n",
      "259 : particular\n",
      "6 : to\n",
      "2712 : interest\n",
      "14 : me\n",
      "24 : on\n"
     ]
    }
   ],
   "source": [
    "for i in sequences[0]:\n",
    "    print(f\"{i} : {tokenizer.index_word[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ffc4014-318c-4681-af4d-4db8be9ae5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d19cb80c-6ed0-4650-ac45-bad33af6dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0f2f077-fea8-44b0-aaba-275eba4abafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2717"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19e34f97-e4a4-4321-90d2-13d7aeeaf67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a1506ea-2312-4291-b846-b7899362a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecbd756b-cab6-45d3-abba-6bd52f20b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "303f4b7e-4ac0-47f8-a55d-dac43fb5c2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 956,   14,  263, ..., 2712,   14,   24],\n",
       "       [  14,  263,   51, ...,   14,   24,  957],\n",
       "       [ 263,   51,  261, ...,   24,  957,    5],\n",
       "       ...,\n",
       "       [ 952,   12,  166, ...,  262,   53,    2],\n",
       "       [  12,  166, 2711, ...,   53,    2, 2717],\n",
       "       [ 166, 2711,    3, ...,    2, 2717,   26]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "284eb18c-b940-43e1-818c-6c619f918c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aee2fba3-94fb-463d-9f21-cd7007c6857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e2f54be-26c4-4a2e-8617-45652e668e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1e660ce-6bad-4a6a-8050-519d3558301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocabulary_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c055e65d-5488-4639-a262-c833992a8d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len= X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2a2bf32-1a89-4b7d-89f1-940f45ebec92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11312, 25)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f6519c3-efd2-411f-85c4-eaf79da169dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ded0bc2-198d-42fa-adeb-7722aabf14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size,seq_len):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size,seq_len, input_length=seq_len))\n",
    "    model.add(LSTM(seq_len*2,return_sequences=True))\n",
    "    model.add(LSTM(seq_len*2))\n",
    "    model.add(Dense(50,activation='relu'))\n",
    "    \n",
    "    model.add(Dense(vocabulary_size,activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5889d367-24de-4183-a4fb-be6497ce39a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 25)            67950     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 25, 50)            15200     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2718)              138618    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 244,518\n",
      "Trainable params: 244,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_size+1,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93b0044a-f5d1-4de4-8841-d07628463ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69af50bf-73bb-435e-8f29-33492b1ac2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "89/89 [==============================] - 4s 10ms/step - loss: 6.9773 - accuracy: 0.0426\n",
      "Epoch 2/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 6.3745 - accuracy: 0.0529\n",
      "Epoch 3/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 6.3450 - accuracy: 0.0529\n",
      "Epoch 4/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 6.2839 - accuracy: 0.0529\n",
      "Epoch 5/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 6.1760 - accuracy: 0.0529\n",
      "Epoch 6/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 6.1111 - accuracy: 0.0530\n",
      "Epoch 7/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 6.0571 - accuracy: 0.0526\n",
      "Epoch 8/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.9786 - accuracy: 0.0551\n",
      "Epoch 9/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.8964 - accuracy: 0.0598\n",
      "Epoch 10/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.8366 - accuracy: 0.0633\n",
      "Epoch 11/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.7804 - accuracy: 0.0670\n",
      "Epoch 12/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.7267 - accuracy: 0.0670\n",
      "Epoch 13/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.6769 - accuracy: 0.0668\n",
      "Epoch 14/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.6332 - accuracy: 0.0693\n",
      "Epoch 15/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.5952 - accuracy: 0.0690\n",
      "Epoch 16/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.5576 - accuracy: 0.0721\n",
      "Epoch 17/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.5271 - accuracy: 0.0728\n",
      "Epoch 18/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.4943 - accuracy: 0.0750\n",
      "Epoch 19/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.4672 - accuracy: 0.0753\n",
      "Epoch 20/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.4388 - accuracy: 0.0774\n",
      "Epoch 21/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.4129 - accuracy: 0.0783\n",
      "Epoch 22/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.3871 - accuracy: 0.0796\n",
      "Epoch 23/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.3590 - accuracy: 0.0790\n",
      "Epoch 24/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.3320 - accuracy: 0.0812\n",
      "Epoch 25/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.3049 - accuracy: 0.0817\n",
      "Epoch 26/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.2703 - accuracy: 0.0829\n",
      "Epoch 27/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.2359 - accuracy: 0.0837\n",
      "Epoch 28/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.2023 - accuracy: 0.0862\n",
      "Epoch 29/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.1700 - accuracy: 0.0880\n",
      "Epoch 30/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.1339 - accuracy: 0.0896\n",
      "Epoch 31/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.1002 - accuracy: 0.0908\n",
      "Epoch 32/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.0659 - accuracy: 0.0919\n",
      "Epoch 33/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.0345 - accuracy: 0.0954\n",
      "Epoch 34/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.9994 - accuracy: 0.0973\n",
      "Epoch 35/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.9674 - accuracy: 0.0982\n",
      "Epoch 36/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.9354 - accuracy: 0.1025\n",
      "Epoch 37/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.8983 - accuracy: 0.1042\n",
      "Epoch 38/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.8682 - accuracy: 0.1040\n",
      "Epoch 39/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.8353 - accuracy: 0.1074\n",
      "Epoch 40/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.8018 - accuracy: 0.1089\n",
      "Epoch 41/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.7700 - accuracy: 0.1100\n",
      "Epoch 42/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.7427 - accuracy: 0.1144\n",
      "Epoch 43/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.7102 - accuracy: 0.1165\n",
      "Epoch 44/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.6754 - accuracy: 0.1178\n",
      "Epoch 45/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.6434 - accuracy: 0.1183\n",
      "Epoch 46/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.6082 - accuracy: 0.1254\n",
      "Epoch 47/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.5764 - accuracy: 0.1227\n",
      "Epoch 48/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.5470 - accuracy: 0.1252\n",
      "Epoch 49/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.5147 - accuracy: 0.1251\n",
      "Epoch 50/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.4802 - accuracy: 0.1284\n",
      "Epoch 51/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.4463 - accuracy: 0.1321\n",
      "Epoch 52/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.4188 - accuracy: 0.1300\n",
      "Epoch 53/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.3902 - accuracy: 0.1334\n",
      "Epoch 54/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.3556 - accuracy: 0.1357\n",
      "Epoch 55/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.3393 - accuracy: 0.1364\n",
      "Epoch 56/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.3015 - accuracy: 0.1399\n",
      "Epoch 57/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.2693 - accuracy: 0.1414\n",
      "Epoch 58/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.2415 - accuracy: 0.1418\n",
      "Epoch 59/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.2157 - accuracy: 0.1474\n",
      "Epoch 60/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.1862 - accuracy: 0.1460\n",
      "Epoch 61/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.1557 - accuracy: 0.1485\n",
      "Epoch 62/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 4.1423 - accuracy: 0.1478\n",
      "Epoch 63/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.1110 - accuracy: 0.1503\n",
      "Epoch 64/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.0713 - accuracy: 0.1531\n",
      "Epoch 65/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.0502 - accuracy: 0.1548\n",
      "Epoch 66/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.0203 - accuracy: 0.1590\n",
      "Epoch 67/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 4.0010 - accuracy: 0.1586\n",
      "Epoch 68/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.9781 - accuracy: 0.1604\n",
      "Epoch 69/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.9518 - accuracy: 0.1657\n",
      "Epoch 70/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.9281 - accuracy: 0.1681\n",
      "Epoch 71/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.9039 - accuracy: 0.1675\n",
      "Epoch 72/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.8726 - accuracy: 0.1709\n",
      "Epoch 73/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.8491 - accuracy: 0.1748\n",
      "Epoch 74/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.8252 - accuracy: 0.1771\n",
      "Epoch 75/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.8117 - accuracy: 0.1800\n",
      "Epoch 76/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.7806 - accuracy: 0.1795\n",
      "Epoch 77/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.7552 - accuracy: 0.1838\n",
      "Epoch 78/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.7320 - accuracy: 0.1894\n",
      "Epoch 79/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.7069 - accuracy: 0.1923\n",
      "Epoch 80/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.6880 - accuracy: 0.1917\n",
      "Epoch 81/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.6566 - accuracy: 0.1976\n",
      "Epoch 82/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.6360 - accuracy: 0.2017\n",
      "Epoch 83/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.6085 - accuracy: 0.2048\n",
      "Epoch 84/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.5832 - accuracy: 0.2062\n",
      "Epoch 85/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.5713 - accuracy: 0.2060\n",
      "Epoch 86/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.5411 - accuracy: 0.2137\n",
      "Epoch 87/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.5187 - accuracy: 0.2169\n",
      "Epoch 88/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.4940 - accuracy: 0.2207\n",
      "Epoch 89/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.4665 - accuracy: 0.2252\n",
      "Epoch 90/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.4482 - accuracy: 0.2250\n",
      "Epoch 91/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.4202 - accuracy: 0.2342\n",
      "Epoch 92/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.3940 - accuracy: 0.2339\n",
      "Epoch 93/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.3715 - accuracy: 0.2369\n",
      "Epoch 94/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.3485 - accuracy: 0.2405\n",
      "Epoch 95/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.3207 - accuracy: 0.2461\n",
      "Epoch 96/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.2977 - accuracy: 0.2519\n",
      "Epoch 97/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.2724 - accuracy: 0.2555\n",
      "Epoch 98/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.2597 - accuracy: 0.2550\n",
      "Epoch 99/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.2328 - accuracy: 0.2631\n",
      "Epoch 100/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.2173 - accuracy: 0.2630\n",
      "Epoch 101/350\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 3.1887 - accuracy: 0.2673\n",
      "Epoch 102/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.1664 - accuracy: 0.2745\n",
      "Epoch 103/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.1485 - accuracy: 0.2778\n",
      "Epoch 104/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.1299 - accuracy: 0.2836\n",
      "Epoch 105/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.1083 - accuracy: 0.2837\n",
      "Epoch 106/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.0803 - accuracy: 0.2947\n",
      "Epoch 107/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.0655 - accuracy: 0.2944\n",
      "Epoch 108/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.0460 - accuracy: 0.2956\n",
      "Epoch 109/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.0265 - accuracy: 0.3020\n",
      "Epoch 110/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.0155 - accuracy: 0.3034\n",
      "Epoch 111/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 3.0003 - accuracy: 0.3045\n",
      "Epoch 112/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.9786 - accuracy: 0.3079\n",
      "Epoch 113/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.9605 - accuracy: 0.3118\n",
      "Epoch 114/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.9465 - accuracy: 0.3145\n",
      "Epoch 115/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.9310 - accuracy: 0.3166\n",
      "Epoch 116/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.9153 - accuracy: 0.3195\n",
      "Epoch 117/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.8963 - accuracy: 0.3253\n",
      "Epoch 118/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.8722 - accuracy: 0.3307\n",
      "Epoch 119/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.8539 - accuracy: 0.3300\n",
      "Epoch 120/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.8387 - accuracy: 0.3369\n",
      "Epoch 121/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.8238 - accuracy: 0.3379\n",
      "Epoch 122/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.8085 - accuracy: 0.3415\n",
      "Epoch 123/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.7897 - accuracy: 0.3451\n",
      "Epoch 124/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.7796 - accuracy: 0.3482\n",
      "Epoch 125/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.7717 - accuracy: 0.3486\n",
      "Epoch 126/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.7590 - accuracy: 0.3533\n",
      "Epoch 127/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.7389 - accuracy: 0.3540\n",
      "Epoch 128/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.7231 - accuracy: 0.3587\n",
      "Epoch 129/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.7118 - accuracy: 0.3618\n",
      "Epoch 130/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.6941 - accuracy: 0.3667\n",
      "Epoch 131/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.6834 - accuracy: 0.3670\n",
      "Epoch 132/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.6682 - accuracy: 0.3665\n",
      "Epoch 133/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.6493 - accuracy: 0.3730\n",
      "Epoch 134/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.6531 - accuracy: 0.3712\n",
      "Epoch 135/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.6329 - accuracy: 0.3748\n",
      "Epoch 136/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.6051 - accuracy: 0.3814\n",
      "Epoch 137/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.5915 - accuracy: 0.3855\n",
      "Epoch 138/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.5786 - accuracy: 0.3928\n",
      "Epoch 139/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.5714 - accuracy: 0.3875\n",
      "Epoch 140/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.5555 - accuracy: 0.3927\n",
      "Epoch 141/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.5469 - accuracy: 0.3962\n",
      "Epoch 142/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.5458 - accuracy: 0.3913\n",
      "Epoch 143/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.5227 - accuracy: 0.3983\n",
      "Epoch 144/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.5071 - accuracy: 0.3999\n",
      "Epoch 145/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.4916 - accuracy: 0.4047\n",
      "Epoch 146/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.4785 - accuracy: 0.4070\n",
      "Epoch 147/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.4780 - accuracy: 0.4077\n",
      "Epoch 148/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.4579 - accuracy: 0.4134\n",
      "Epoch 149/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.4454 - accuracy: 0.4133\n",
      "Epoch 150/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.4344 - accuracy: 0.4169\n",
      "Epoch 151/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.4206 - accuracy: 0.4189\n",
      "Epoch 152/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.4205 - accuracy: 0.4168\n",
      "Epoch 153/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.4210 - accuracy: 0.4203\n",
      "Epoch 154/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.3980 - accuracy: 0.4242\n",
      "Epoch 155/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.3679 - accuracy: 0.4327\n",
      "Epoch 156/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.3591 - accuracy: 0.4291\n",
      "Epoch 157/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.3459 - accuracy: 0.4355\n",
      "Epoch 158/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.3432 - accuracy: 0.4351\n",
      "Epoch 159/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.3224 - accuracy: 0.4417\n",
      "Epoch 160/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.3162 - accuracy: 0.4455\n",
      "Epoch 161/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.3287 - accuracy: 0.4371\n",
      "Epoch 162/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.2983 - accuracy: 0.4463\n",
      "Epoch 163/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.2851 - accuracy: 0.4457\n",
      "Epoch 164/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.2811 - accuracy: 0.4492\n",
      "Epoch 165/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.2807 - accuracy: 0.4515\n",
      "Epoch 166/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.2562 - accuracy: 0.4524\n",
      "Epoch 167/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.2409 - accuracy: 0.4587\n",
      "Epoch 168/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.2278 - accuracy: 0.4619\n",
      "Epoch 169/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.2176 - accuracy: 0.4637\n",
      "Epoch 170/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.2035 - accuracy: 0.4664\n",
      "Epoch 171/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.2000 - accuracy: 0.4689\n",
      "Epoch 172/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.2241 - accuracy: 0.4576\n",
      "Epoch 173/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.1866 - accuracy: 0.4734\n",
      "Epoch 174/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.1823 - accuracy: 0.4689\n",
      "Epoch 175/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.1504 - accuracy: 0.4801\n",
      "Epoch 176/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.1342 - accuracy: 0.4802\n",
      "Epoch 177/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.1460 - accuracy: 0.4816\n",
      "Epoch 178/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.1411 - accuracy: 0.4783\n",
      "Epoch 179/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.1204 - accuracy: 0.4826\n",
      "Epoch 180/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.1112 - accuracy: 0.4887\n",
      "Epoch 181/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.1014 - accuracy: 0.4874\n",
      "Epoch 182/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.0876 - accuracy: 0.4949\n",
      "Epoch 183/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.0892 - accuracy: 0.4902\n",
      "Epoch 184/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.0733 - accuracy: 0.4943\n",
      "Epoch 185/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.0617 - accuracy: 0.4983\n",
      "Epoch 186/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.0672 - accuracy: 0.4973\n",
      "Epoch 187/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.0369 - accuracy: 0.5049\n",
      "Epoch 188/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.0378 - accuracy: 0.5029\n",
      "Epoch 189/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.0226 - accuracy: 0.5065\n",
      "Epoch 190/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.0076 - accuracy: 0.5074\n",
      "Epoch 191/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 2.0001 - accuracy: 0.5111\n",
      "Epoch 192/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.9942 - accuracy: 0.5142\n",
      "Epoch 193/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.9920 - accuracy: 0.5122\n",
      "Epoch 194/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.9820 - accuracy: 0.5134\n",
      "Epoch 195/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.9825 - accuracy: 0.5132\n",
      "Epoch 196/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.9625 - accuracy: 0.5192\n",
      "Epoch 197/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.9549 - accuracy: 0.5218\n",
      "Epoch 198/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.9350 - accuracy: 0.5263\n",
      "Epoch 199/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.9299 - accuracy: 0.5264\n",
      "Epoch 200/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.9332 - accuracy: 0.5272\n",
      "Epoch 201/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.9186 - accuracy: 0.5302\n",
      "Epoch 202/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.9089 - accuracy: 0.5308\n",
      "Epoch 203/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.8946 - accuracy: 0.5339\n",
      "Epoch 204/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.8852 - accuracy: 0.5395\n",
      "Epoch 205/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.8810 - accuracy: 0.5379\n",
      "Epoch 206/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.8741 - accuracy: 0.5376\n",
      "Epoch 207/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.8585 - accuracy: 0.5417\n",
      "Epoch 208/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.8590 - accuracy: 0.5450\n",
      "Epoch 209/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.8391 - accuracy: 0.5448\n",
      "Epoch 210/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.8337 - accuracy: 0.5457\n",
      "Epoch 211/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.8590 - accuracy: 0.5400\n",
      "Epoch 212/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.8326 - accuracy: 0.5452\n",
      "Epoch 213/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.8114 - accuracy: 0.5507\n",
      "Epoch 214/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.7993 - accuracy: 0.5568\n",
      "Epoch 215/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.7903 - accuracy: 0.5610\n",
      "Epoch 216/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.7898 - accuracy: 0.5547\n",
      "Epoch 217/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.7731 - accuracy: 0.5631\n",
      "Epoch 218/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.7648 - accuracy: 0.5637\n",
      "Epoch 219/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.7639 - accuracy: 0.5645\n",
      "Epoch 220/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.7493 - accuracy: 0.5690\n",
      "Epoch 221/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.7627 - accuracy: 0.5620\n",
      "Epoch 222/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.7678 - accuracy: 0.5605\n",
      "Epoch 223/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.7499 - accuracy: 0.5637\n",
      "Epoch 224/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.7292 - accuracy: 0.5715\n",
      "Epoch 225/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.7113 - accuracy: 0.5789\n",
      "Epoch 226/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.7027 - accuracy: 0.5757\n",
      "Epoch 227/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.6903 - accuracy: 0.5769\n",
      "Epoch 228/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.6895 - accuracy: 0.5788\n",
      "Epoch 229/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.6898 - accuracy: 0.5775\n",
      "Epoch 230/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.6664 - accuracy: 0.5895\n",
      "Epoch 231/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.6588 - accuracy: 0.5858\n",
      "Epoch 232/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.6489 - accuracy: 0.5911\n",
      "Epoch 233/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.6410 - accuracy: 0.5907\n",
      "Epoch 234/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.6349 - accuracy: 0.5954\n",
      "Epoch 235/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.6236 - accuracy: 0.5949\n",
      "Epoch 236/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.6240 - accuracy: 0.5934\n",
      "Epoch 237/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.6280 - accuracy: 0.5936\n",
      "Epoch 238/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.6128 - accuracy: 0.5949\n",
      "Epoch 239/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.6136 - accuracy: 0.5972\n",
      "Epoch 240/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5871 - accuracy: 0.6023\n",
      "Epoch 241/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5806 - accuracy: 0.6081\n",
      "Epoch 242/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5806 - accuracy: 0.6016\n",
      "Epoch 243/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5744 - accuracy: 0.6070\n",
      "Epoch 244/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5760 - accuracy: 0.6055\n",
      "Epoch 245/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5568 - accuracy: 0.6121\n",
      "Epoch 246/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5519 - accuracy: 0.6117\n",
      "Epoch 247/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5459 - accuracy: 0.6107\n",
      "Epoch 248/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5456 - accuracy: 0.6149\n",
      "Epoch 249/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5300 - accuracy: 0.6174\n",
      "Epoch 250/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5210 - accuracy: 0.6218\n",
      "Epoch 251/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5128 - accuracy: 0.6210\n",
      "Epoch 252/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5098 - accuracy: 0.6250\n",
      "Epoch 253/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4965 - accuracy: 0.6268\n",
      "Epoch 254/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.5009 - accuracy: 0.6231\n",
      "Epoch 255/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4979 - accuracy: 0.6225\n",
      "Epoch 256/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4812 - accuracy: 0.6300\n",
      "Epoch 257/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4681 - accuracy: 0.6358\n",
      "Epoch 258/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4869 - accuracy: 0.6235\n",
      "Epoch 259/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4551 - accuracy: 0.6345\n",
      "Epoch 260/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4724 - accuracy: 0.6254\n",
      "Epoch 261/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4559 - accuracy: 0.6346\n",
      "Epoch 262/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4327 - accuracy: 0.6416\n",
      "Epoch 263/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4330 - accuracy: 0.6402\n",
      "Epoch 264/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4320 - accuracy: 0.6425\n",
      "Epoch 265/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4231 - accuracy: 0.6437\n",
      "Epoch 266/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4184 - accuracy: 0.6421\n",
      "Epoch 267/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.4025 - accuracy: 0.6482\n",
      "Epoch 268/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3888 - accuracy: 0.6489\n",
      "Epoch 269/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3811 - accuracy: 0.6543\n",
      "Epoch 270/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3810 - accuracy: 0.6519\n",
      "Epoch 271/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3900 - accuracy: 0.6504\n",
      "Epoch 272/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3833 - accuracy: 0.6521\n",
      "Epoch 273/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3742 - accuracy: 0.6548\n",
      "Epoch 274/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3613 - accuracy: 0.6579\n",
      "Epoch 275/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3563 - accuracy: 0.6568\n",
      "Epoch 276/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3448 - accuracy: 0.6616\n",
      "Epoch 277/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3249 - accuracy: 0.6673\n",
      "Epoch 278/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3170 - accuracy: 0.6693\n",
      "Epoch 279/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3210 - accuracy: 0.6685\n",
      "Epoch 280/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3236 - accuracy: 0.6665\n",
      "Epoch 281/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3399 - accuracy: 0.6630\n",
      "Epoch 282/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3408 - accuracy: 0.6598\n",
      "Epoch 283/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3415 - accuracy: 0.6625\n",
      "Epoch 284/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.3191 - accuracy: 0.6673\n",
      "Epoch 285/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2831 - accuracy: 0.6792\n",
      "Epoch 286/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2562 - accuracy: 0.6872\n",
      "Epoch 287/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2628 - accuracy: 0.6823\n",
      "Epoch 288/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2530 - accuracy: 0.6858\n",
      "Epoch 289/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2535 - accuracy: 0.6871\n",
      "Epoch 290/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2632 - accuracy: 0.6838\n",
      "Epoch 291/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2441 - accuracy: 0.6887\n",
      "Epoch 292/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2377 - accuracy: 0.6875\n",
      "Epoch 293/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2308 - accuracy: 0.6905\n",
      "Epoch 294/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2318 - accuracy: 0.6880\n",
      "Epoch 295/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2354 - accuracy: 0.6904\n",
      "Epoch 296/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2285 - accuracy: 0.6912\n",
      "Epoch 297/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2005 - accuracy: 0.6986\n",
      "Epoch 298/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.1861 - accuracy: 0.7046\n",
      "Epoch 299/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.1966 - accuracy: 0.6990\n",
      "Epoch 300/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2287 - accuracy: 0.6853\n",
      "Epoch 301/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.2191 - accuracy: 0.6888\n",
      "Epoch 302/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.1911 - accuracy: 0.6983\n",
      "Epoch 303/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.1730 - accuracy: 0.7059\n",
      "Epoch 304/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.1690 - accuracy: 0.7085\n",
      "Epoch 305/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.1551 - accuracy: 0.7102\n",
      "Epoch 306/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.1518 - accuracy: 0.7071\n",
      "Epoch 307/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.1510 - accuracy: 0.7099\n",
      "Epoch 308/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.1389 - accuracy: 0.7128\n",
      "Epoch 309/350\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.1509 - accuracy: 0.7118\n",
      "Epoch 310/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.1310 - accuracy: 0.7172\n",
      "Epoch 311/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.1239 - accuracy: 0.7182\n",
      "Epoch 312/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.1250 - accuracy: 0.7157\n",
      "Epoch 313/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.1245 - accuracy: 0.7113\n",
      "Epoch 314/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.1065 - accuracy: 0.7247\n",
      "Epoch 315/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.1788 - accuracy: 0.6981\n",
      "Epoch 316/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.1460 - accuracy: 0.7055\n",
      "Epoch 317/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.1235 - accuracy: 0.7130\n",
      "Epoch 318/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.1177 - accuracy: 0.7178\n",
      "Epoch 319/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.1041 - accuracy: 0.7209\n",
      "Epoch 320/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0910 - accuracy: 0.7257\n",
      "Epoch 321/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0705 - accuracy: 0.7314\n",
      "Epoch 322/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0592 - accuracy: 0.7362\n",
      "Epoch 323/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0359 - accuracy: 0.7420\n",
      "Epoch 324/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0292 - accuracy: 0.7403\n",
      "Epoch 325/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0274 - accuracy: 0.7454\n",
      "Epoch 326/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0312 - accuracy: 0.7443\n",
      "Epoch 327/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0316 - accuracy: 0.7405\n",
      "Epoch 328/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0306 - accuracy: 0.7391\n",
      "Epoch 329/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0356 - accuracy: 0.7381\n",
      "Epoch 330/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0409 - accuracy: 0.7365\n",
      "Epoch 331/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0425 - accuracy: 0.7376\n",
      "Epoch 332/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0171 - accuracy: 0.7464\n",
      "Epoch 333/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0145 - accuracy: 0.7428\n",
      "Epoch 334/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0174 - accuracy: 0.7412\n",
      "Epoch 335/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0075 - accuracy: 0.7447\n",
      "Epoch 336/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0120 - accuracy: 0.7450\n",
      "Epoch 337/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0030 - accuracy: 0.7462\n",
      "Epoch 338/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0011 - accuracy: 0.7460\n",
      "Epoch 339/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0339 - accuracy: 0.7336\n",
      "Epoch 340/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1.0111 - accuracy: 0.7445\n",
      "Epoch 341/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.9794 - accuracy: 0.7504\n",
      "Epoch 342/350\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.9511 - accuracy: 0.7647\n",
      "Epoch 343/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.9333 - accuracy: 0.7677\n",
      "Epoch 344/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.9318 - accuracy: 0.7702\n",
      "Epoch 345/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.9441 - accuracy: 0.7675\n",
      "Epoch 346/350\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.9337 - accuracy: 0.7661\n",
      "Epoch 347/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.9418 - accuracy: 0.7638\n",
      "Epoch 348/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.9361 - accuracy: 0.7666\n",
      "Epoch 349/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.9299 - accuracy: 0.7682\n",
      "Epoch 350/350\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.9074 - accuracy: 0.7738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cd86836ca0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,batch_size=128, epochs=350, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b5f66b5-bfb6-420c-b3d6-16cd19bb0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_mobydick_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9dd7780-c49d-4191-b471-1151457b3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tokenizer,open('my_simpletokenizer', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "966b76cf-45ce-4eb0-889b-1933f9099e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0187b5bf-7d7c-4cd6-a81c-cd7694019929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    model : model that was trained on text data\n",
    "    tokenizer : tokenizer that was fit on text data\n",
    "    seq_len : length of training sequence\n",
    "    seed_text : raw string text to serve as the seed\n",
    "    num_gen_words : number of words to be generated by model\n",
    "    '''\n",
    "    \n",
    "    # Final Output\n",
    "    output_text = []\n",
    "    \n",
    "    # Intial Seed Sequence\n",
    "    input_text = seed_text\n",
    "    \n",
    "    # Create num_gen_words\n",
    "    for i in range(num_gen_words):\n",
    "        \n",
    "        # Take the input text string and encode it to a sequence\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        \n",
    "        # Pad sequences to our trained rate (50 words in the video)\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        \n",
    "        # Predict Class Probabilities for each word\n",
    "        pred_word_ind = np.argmax(model.predict(pad_encoded, verbose=0)[0], axis=0)\n",
    "        \n",
    "        # Grab word\n",
    "        pred_word = tokenizer.index_word[pred_word_ind] \n",
    "        \n",
    "        # Update the sequence of input text (shifting one over with the new word)\n",
    "        input_text += ' ' + pred_word\n",
    "        \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    # Make it look like a sentence.\n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f5c562f6-acb8-4353-8300-2064dfdd6a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how',\n",
       " 'long',\n",
       " 'precisely',\n",
       " 'having',\n",
       " 'little',\n",
       " 'or',\n",
       " 'no',\n",
       " 'money',\n",
       " 'in',\n",
       " 'my',\n",
       " 'purse',\n",
       " 'and',\n",
       " 'nothing',\n",
       " 'particular',\n",
       " 'to',\n",
       " 'interest',\n",
       " 'me',\n",
       " 'on']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9102ccd8-34dd-43b4-9f98-40e380882251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(101)\n",
    "random_pick = random.randint(0,len(text_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f44bd502-0718-443c-a885-4578b4d13a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed_text = text_sequences[random_pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b065ed2a-75e9-475c-8e68-e7d0c03f07d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thought',\n",
       " 'i',\n",
       " 'to',\n",
       " 'myself',\n",
       " 'the',\n",
       " 'man',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'human',\n",
       " 'being',\n",
       " 'just',\n",
       " 'as',\n",
       " 'i',\n",
       " 'am',\n",
       " 'he',\n",
       " 'has',\n",
       " 'just',\n",
       " 'as',\n",
       " 'much',\n",
       " 'reason',\n",
       " 'to',\n",
       " 'fear',\n",
       " 'me',\n",
       " 'as',\n",
       " 'i',\n",
       " 'have']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "620b5414-30eb-4ab6-965a-71f952842873",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = ' '.join(random_seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5966e224-89d2-4431-94cf-b7d80bc1daf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"thought i to myself the man 's a human being just as i am he has just as much reason to fear me as i have\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ac0300e-79ef-46f2-bcd2-2394ec2b0331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"to be afraid of him then to spoil the hilarity of his shipmates and presently the plane take in the year in his chest he save the good hunch or a dream but had are her kept it i wo n't see him piled whoever and put more crowds for\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3dac1-267d-49ce-9385-5271aa9b78fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
